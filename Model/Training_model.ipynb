{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Training_model.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "02ZHJuNgQvvK"
      },
      "source": [
        "!pip install https://github.com/CellProfiling/HPA-Cell-Segmentation/archive/master.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wI-E263QQvvQ"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import hpacellseg.cellsegmentator as cellsegmentator\n",
        "from hpacellseg.utils import label_cell, label_nuclei"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaBRKtfOQvvQ"
      },
      "source": [
        "# **FUNCTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yNLy21KHQvvR"
      },
      "source": [
        "# Input: list of image filters as png\n",
        "# Output: list of image filters as np.arrays\n",
        "def image_to_arrays(path):\n",
        "    \n",
        "    image_arrays = list()\n",
        "    for image in path:\n",
        "        array = np.asarray(Image.open(image))\n",
        "        image_arrays.append(array)\n",
        "        \n",
        "    return image_arrays"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "r_vBSTSXQvvR"
      },
      "source": [
        "# Get single image that blends all RGBY into RGB\n",
        "# Introduce the images as arrays. Can use the function above.\n",
        "\n",
        "def get_blended_image(images): \n",
        "    # get rgby images for sample\n",
        "\n",
        "    # blend rgby images into single array\n",
        "    blended_array = np.stack(images[:-1], 2)\n",
        "\n",
        "    # Create PIL Image\n",
        "    blended_image = Image.fromarray( np.uint8(blended_array) )\n",
        "    return blended_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8diKuIRkQvvS"
      },
      "source": [
        "# Introduce list of image filters\n",
        "# Returns a processed image ready for the CNN and an encoded label as tensor\n",
        "def image_prep(paths, label):\n",
        "\n",
        "    img = image_to_arrays(paths)\n",
        "    size = np.shape(img[0])[0]\n",
        "    img = tf.image.convert_image_dtype(img, dtype=tf.float32)\n",
        "    img = tf.reshape(img, (1, size, size, 3))\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "\n",
        "    label = tf.strings.split(label, sep='|')\n",
        "    label = tf.strings.to_number(label, out_type=tf.int32)\n",
        "    label = tf.reduce_sum(tf.one_hot(indices=label, depth=19), axis=0)\n",
        "    label = tf.reshape(label, (1, 19))\n",
        "    \n",
        "    return img, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AR6lPBgAQvvS"
      },
      "source": [
        "def apply_augmentation(image, label):\n",
        "    aug_img = tf.numpy_function(func=aug_fn, inp=[image], Tout=tf.float32)\n",
        "    aug_img.set_shape((IMG_SIZE[0], IMG_SIZE[0], 3))\n",
        "    \n",
        "    return aug_img, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0FQ1J2juQvvS"
      },
      "source": [
        "def plot_hist(hist):\n",
        "    plt.plot(hist.history[\"auc\"])\n",
        "    plt.plot(hist.history[\"val_auc\"])\n",
        "    plt.title(\"model auc\")\n",
        "    plt.ylabel(\"auc\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fn2S9UP3QvvT"
      },
      "source": [
        "DATA_DIR = \"/kaggle/input/hpa-single-cell-image-classification\"\n",
        "\n",
        "train = pd.read_csv(os.path.join(DATA_DIR,'train.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Xabbqgm5QvvT"
      },
      "source": [
        "colours = ['_red.png', '_blue.png', '_yellow.png', '_green.png']\n",
        "TRAIN = '../input/hpa-single-cell-image-classification/train'\n",
        "paths = [[os.path.join(TRAIN, train.iloc[idx,0])+ colour for colour in colours] for idx in range(len(train))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkHqD09gQvvT"
      },
      "source": [
        "# *Data Analisys...*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BypfPB4CQvvU"
      },
      "source": [
        "# Let's check out the label distribution frequency.\n",
        "labels = []\n",
        "for label in train['Label']:\n",
        "    sep = label.split('|')\n",
        "    for num in sep:\n",
        "        labels.append(int(num))\n",
        "counts = pd.value_counts(labels)\n",
        "\n",
        "# It's an ugly plot, but I'm trying to save some time here...\n",
        "plt.bar(x = counts.index,height=counts)\n",
        "plt.xticks(counts.index)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GLURNi8nQvvU"
      },
      "source": [
        "titles = ['microtubules', 'nuclei', 'endoplasmic reticulum', 'protein of interest']\n",
        "fig, axs = plt.subplots(3, 4, figsize =(16,8))\n",
        "for entry in range(3):\n",
        "    for channel in range(4):\n",
        "        img = plt.imread(paths[entry][channel])\n",
        "        axs[entry, channel].imshow(img)        \n",
        "        if entry == 0:\n",
        "            axs[0, channel].set_title(titles[channel])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1eld44jQvvU"
      },
      "source": [
        "# **Segmentation using [HPA-Cell-Segmentation](https://github.com/CellProfiling/HPA-Cell-Segmentation)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CBZaDM2BQvvV"
      },
      "source": [
        "NUC_MODEL = \"./nuclei-model.pth\"\n",
        "CELL_MODEL = \"./cell-model.pth\"\n",
        "segmentator = cellsegmentator.CellSegmentator(\n",
        "    NUC_MODEL,\n",
        "    CELL_MODEL,\n",
        "    scale_factor=0.25,\n",
        "    device=\"cuda\",\n",
        "    padding=False,\n",
        "    multi_channel_model=True,\n",
        ")\n",
        "\n",
        "image = paths[4]\n",
        "arrays = image_to_arrays(image)\n",
        "nuclei = arrays[1]\n",
        "cell = arrays[:-1]\n",
        "\n",
        "# Nuclei segmentation\n",
        "nuc_segmentations = segmentator.pred_nuclei([nuclei])\n",
        "\n",
        "f, ax = plt.subplots(1, 2, figsize=(16,16))\n",
        "ax[0].imshow(arrays[1])\n",
        "ax[0].set_title('Original Nucleis', size=20)\n",
        "ax[1].imshow(nuc_segmentations[0])\n",
        "ax[1].set_title('Segmented Nucleis', size=20)\n",
        "plt.show()\n",
        "\n",
        "# Cell segmentation\n",
        "inter_step = [[i] for i in image[:-1]]\n",
        "cell_segmentations = segmentator.pred_cells(inter_step)\n",
        "\n",
        "f, ax = plt.subplots(1, 2, figsize=(16,16))\n",
        "ax[0].imshow(get_blended_image(arrays))\n",
        "ax[0].set_title('Original Cells', size=20)\n",
        "ax[1].imshow(cell_segmentations[0])\n",
        "ax[1].set_title('Segmented Cells', size=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2slaWvuHQvvV"
      },
      "source": [
        "# **Visualizing the masks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vCrwJpETQvvV"
      },
      "source": [
        "# Nuclei mask\n",
        "nuclei_mask = label_nuclei(nuc_segmentations[0])\n",
        "# Cell masks\n",
        "cell_nuclei_mask, cell_mask = label_cell(nuc_segmentations[0], cell_segmentations[0])\n",
        "# Plotting\n",
        "f, ax = plt.subplots(1, 3, figsize=(16,16))\n",
        "ax[0].imshow(nuclei_mask)\n",
        "ax[0].set_title('Nuclei Mask', size=20)\n",
        "ax[1].imshow(cell_nuclei_mask)\n",
        "ax[1].set_title('Cell Nuclei Mask', size=20)\n",
        "ax[2].imshow(cell_mask)\n",
        "ax[2].set_title('Cell Mask', size=20)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kahBGE0IQvvW"
      },
      "source": [
        "Let's check the results of the segmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7A_34YfqQvvW"
      },
      "source": [
        "# Let's stack the original image and the segmentation mask, to see how the segmentation worked out\n",
        "plt.figure(figsize=(20,20))\n",
        "plt.imshow(get_blended_image(arrays))\n",
        "plt.imshow(cell_mask, alpha=0.5)\n",
        "plt.title('Segmentation results', size=40)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfGfekPIQvvW"
      },
      "source": [
        "# **Cell separation**\n",
        "\n",
        "The objective of this project is to label each cell in the image. Therefore each cell in the image must be separated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vWi9n4MvQvvW"
      },
      "source": [
        "# Unique vector of cell_mask numbers\n",
        "numbers = set(np.ravel(cell_mask))\n",
        "numbers.remove(0)\n",
        "\n",
        "fig = plt.figure(figsize=(25,6*len(numbers)/4))\n",
        "index = 1\n",
        "\n",
        "ax = fig.add_subplot(len(numbers)//4+1, 4, index)\n",
        "ax.set_title(\"Complete Cell Mask\", size=20)\n",
        "plt.imshow(cell_mask)\n",
        "\n",
        "index += 1\n",
        "for number in numbers:\n",
        "    isolated_cell = np.where(cell_mask==number, cell_mask, 0)\n",
        "    ax = fig.add_subplot(len(numbers)//4+1, 4, index)\n",
        "    ax.set_title(\"Segment {number}\", size=20)\n",
        "    plt.imshow(isolated_cell)\n",
        "    index += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro8oxjwnQvvX"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bNAyAFTQvvX"
      },
      "source": [
        "Imports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eQ8Z8fmGQvvX"
      },
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TLzVJZMpQvvY"
      },
      "source": [
        "LABELS= {\n",
        "0: \"Nucleoplasm\",\n",
        "1: \"Nuclear membrane\",\n",
        "2: \"Nucleoli\",\n",
        "3: \"Nucleoli fibrillar center\",\n",
        "4: \"Nuclear speckles\",\n",
        "5: \"Nuclear bodies\",\n",
        "6: \"Endoplasmic reticulum\",\n",
        "7: \"Golgi apparatus\",\n",
        "8: \"Intermediate filaments\",\n",
        "9: \"Actin filaments\",\n",
        "10: \"Microtubules\",\n",
        "11: \"Mitotic spindle\",\n",
        "12: \"Centrosome\",\n",
        "13: \"Plasma membrane\",\n",
        "14: \"Mitochondria\",\n",
        "15: \"Aggresome\",\n",
        "16: \"Cytosol\",\n",
        "17: \"Vesicles and punctate cytosolic patterns\",\n",
        "18: \"Negative\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OqRcxtksQvvY"
      },
      "source": [
        "# We'll use EfficientNetB0 model, which requires an image dimension of (224,224,3).Therefor, we can only pass a 3 filter image... \n",
        "#We'll put aside the yellow filter for now.\n",
        "IMG_SIZE = [224, 224]\n",
        "BATCH_SIZE = 64\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "colours = ['_red.png', '_blue.png', '_green.png']\n",
        "TRAIN = '../input/hpa-single-cell-image-classification/train'\n",
        "paths = [[os.path.join(TRAIN, train.iloc[idx,0])+ colour for colour in colours] for idx in range(len(train))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siNCGz-TQvvY"
      },
      "source": [
        "# **Training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lL-2HdB3QvvY"
      },
      "source": [
        "# Processing the data for training:\n",
        "training_data = []\n",
        "for i,path in enumerate(paths[:20000]):\n",
        "    img, label = image_prep(path, train['Label'][i])\n",
        "    training_data.append([img,label])\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(([training_data[i][0] for i in range(len(training_data))], [training_data[i][1] for i in range(len(training_data))]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLGqdtQkQvvY"
      },
      "source": [
        "# **Validation data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zI3Ty4TaQvvZ"
      },
      "source": [
        "val_data = []\n",
        "start_img = 20000\n",
        "val_num = 1800\n",
        "for i,path in enumerate(paths[start_img:start_img+val_num]):\n",
        "    img, label = image_prep(path, train['Label'][i+start_img])\n",
        "    val_data.append([img,label])\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices(([val_data[i][0] for i in range(len(val_data))], [val_data[i][1] for i in range(len(val_data))]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cryocmBQvvZ"
      },
      "source": [
        "# EfficientNetB0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UcP8HB3YQvvZ"
      },
      "source": [
        "base_model = EfficientNetB0(include_top=False, weights='imagenet')\n",
        "base_model.trainable = True\n",
        "\n",
        "inputs = layers.Input((IMG_SIZE[0], IMG_SIZE[0], 3))\n",
        "\n",
        "x = base_model(inputs, training=True)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(len(LABELS), activation='sigmoid')(x)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4WGMXPXwQvvZ"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "import tensorflow_addons as tfa\n",
        "earlystopper = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=10, verbose=0, mode='min',\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# model.compile('adam', 'binary_crossentropy', metrics=[tf.keras.metrics.AUC(multi_label=True)])\n",
        "model.compile('adam', 'binary_crossentropy', metrics=[tf.keras.metrics.AUC(multi_label=True)])\n",
        "#model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
        "#run = wandb.init(entity='ayush-thakur', project='hpa', job_type='train')\n",
        "\n",
        "hist = model.fit(train_ds, \n",
        "          epochs=50,\n",
        "          validation_data=val_ds,\n",
        "          verbose=1,\n",
        "          callbacks=[earlystopper]\n",
        "                )\n",
        "#plot_hist(hist)\n",
        "#run.finish()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CCtgvFtAQvvZ"
      },
      "source": [
        "model.save('effnet_multilabel_BCE.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "I_-F4q1hQvva"
      },
      "source": [
        "# For focal\n",
        "base_model = EfficientNetB0(include_top=False, weights='imagenet')\n",
        "base_model.trainable = True\n",
        "\n",
        "inputs = layers.Input((IMG_SIZE[0], IMG_SIZE[0], 3))\n",
        "\n",
        "x = base_model(inputs, training=True)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(len(LABELS), activation='sigmoid')(x)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model_focal = Model(inputs, outputs)\n",
        "model_focal.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tWu8CT_-Qvva"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "import tensorflow_addons as tfa\n",
        "earlystopper = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=20, verbose=0, mode='min',\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "model_focal.compile('adam', loss=tfa.losses.SigmoidFocalCrossEntropy()])\n",
        "#model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
        "#run = wandb.init(entity='ayush-thakur', project='hpa', job_type='train')\n",
        "\n",
        "# hist_focal = model.fit(train_ds, \n",
        "#           epochs=50,\n",
        "#           validation_data=val_ds,\n",
        "#           verbose=1,\n",
        "#           callbacks=[earlystopper]\n",
        "#                 )\n",
        "\n",
        "hist_focal = model.fit(train_ds, \n",
        "          epochs=50,\n",
        "          validation_data=val_ds,\n",
        "          verbose=1,callbacks=[earlystopper])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KjdqJHpMQvvb"
      },
      "source": [
        "model_focal.save('effnet_multilabel_focal.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kV2un2twQvvb"
      },
      "source": [
        "# shows the result of model loss\n",
        "plt.plot(hist.history[\"loss\"])\n",
        "plt.plot(hist.history[\"val_loss\"])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "# plt.legend([\"BCE_train\", \"BCE_validation\"], loc=\"upper left\")\n",
        "plt.plot(hist_focal.history[\"loss\"])\n",
        "plt.plot(hist_focal.history[\"val_loss\"])\n",
        "# plt.title(\"model loss\")\n",
        "# plt.ylabel(\"loss\")\n",
        "# plt.xlabel(\"epoch\")\n",
        "plt.legend([\"BCE_train\", \"BCE_validation\",\"FL_train\", \"FL_validation\"], loc=\"best\")\n",
        "plt.savefig('model_loss.png')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf2nQ9h8Rg4n"
      },
      "source": [
        "plt.plot(hist.history[\"auc\"])\n",
        "plt.plot(hist.history[\"val_auc\"])\n",
        "plt.title(\"model auc\")\n",
        "plt.ylabel(\"auc\")\n",
        "plt.xlabel(\"epoch\")\n",
        "# plt.legend([\"BCE_train\", \"BCE_validation\"], loc=\"upper left\")\n",
        "plt.plot(hist_focal.history[\"auc\"])\n",
        "plt.plot(hist_focal.history[\"val_auc\"])\n",
        "# plt.title(\"model loss\")\n",
        "# plt.ylabel(\"loss\")\n",
        "# plt.xlabel(\"epoch\")\n",
        "plt.legend([\"BCE_train\", \"BCE_validation\",\"FL_train\", \"FL_validation\"], loc=\"best\")\n",
        "plt.savefig('model_auc.png')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}